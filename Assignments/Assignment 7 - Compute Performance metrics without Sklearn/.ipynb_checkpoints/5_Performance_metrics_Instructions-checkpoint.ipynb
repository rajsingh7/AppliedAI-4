{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : TN = 0,FN = 0, FP = 100 TP = 10000 \n",
      "F1 Score = 0.995\n",
      "Accuracy = 0.99\n",
      "AUC score = 0.488\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_a.csv')\n",
    "dataAUC = pd.read_csv('5_a.csv')\n",
    "\n",
    "data.sort_values(by='proba', ascending=True , inplace = True) #sort data by proba in descending order\n",
    "\n",
    "data['proba'] = np.where(data['proba'] >= 0.5, 1, data['proba'])    #replacing proba with 1 if >= 0.5\n",
    "data['proba'] = np.where(data['proba'] < 0.5, 0, data['proba'])     #replacing proba with 0 if < 0.5\n",
    "\n",
    "data['y'] = data['y'].astype(int)                    #convering to int\n",
    "data['proba'] = data['proba'].astype(int)            #convering to int\n",
    "\n",
    "\n",
    "data_TN = data.query('y == 0 & proba == 0')          #filtering TN\n",
    "data_FN = data.query('y == 1 & proba == 0')          #filtering FN\n",
    "data_FP = data.query('y == 0 & proba == 1')          #filtering FP\n",
    "data_TP = data.query('y == 1 & proba == 1')          #filtering TP\n",
    "\n",
    "TN = data_TN.shape[0]                                #Getting number of records\n",
    "FN = data_FN.shape[0]\n",
    "FP = data_FP.shape[0]\n",
    "TP = data_TP.shape[0]\n",
    "\n",
    "print(\"Confusion Matrix : TN = {},FN = {}, FP = {} TP = {} \".format(TN , FN , FP , TP))     #printing Confusion Matrix\n",
    "\n",
    "pr = TP/(TP+FP)   #Calculating Precision\n",
    "re = TP/(TP+FN)   #Calculating Recall\n",
    "\n",
    "f1 = (2*pr*re)/(pr+re)   #Calculating F1 Score\n",
    "\n",
    "acc = (TN+TP)/(TP+FP+FN+TN)  #Calculating Accuracy Score\n",
    "\n",
    "print(\"F1 Score = {}\".format(round(f1,3)))   #printing F1 Score\n",
    "print(\"Accuracy = {}\".format(round(acc,3)))  #printing Accuracy Score\n",
    "\n",
    "\n",
    "\n",
    "### For AUC Score\n",
    "dataAUC.sort_values(by='proba', ascending=False , inplace = True) #sorting in ascending order of probas\n",
    "\n",
    "arr_proba = np.array(dataAUC.proba.unique()) # array of unique probabilities\n",
    "\n",
    "TPR_Final =  []\n",
    "FPR_Final  = []\n",
    "\n",
    "\n",
    "for i in arr_proba:\n",
    "    data_new_ite = dataAUC.copy()   #used copy to point to different memory location , copying original dataset for every iteration\n",
    "\n",
    "    data_new_ite['proba'] = np.where(data_new_ite['proba'] >= i, 1.0, data_new_ite['proba'])\n",
    "    data_new_ite['proba'] = np.where(data_new_ite['proba'] < i, 0.0, data_new_ite['proba'])\n",
    "    \n",
    "    data_P = data_new_ite.query('y == 1.0')\n",
    "    data_N = data_new_ite.query('y == 0.0')\n",
    "    data_FP = data_new_ite.query('y == 0.0 & proba == 1.0')\n",
    "    data_TP = data_new_ite.query('y == 1.0 & proba == 1.0')\n",
    "    \n",
    "    P = data_P.shape[0]\n",
    "    N = data_N.shape[0]\n",
    "    FP = data_FP.shape[0]\n",
    "    TP = data_TP.shape[0]\n",
    "    \n",
    "    TPR = TP/P\n",
    "    FPR = FP/N\n",
    "    \n",
    "    TPR_Final.append(TPR)   #creating list of TPR for every threshold\n",
    "    FPR_Final.append(FPR)   #creating list of FPR for every threshold\n",
    "    \n",
    "AUCscore = np.trapz(TPR_Final, FPR_Final)  #calculation AUC Score\n",
    "print(\"AUC score = {}\".format(round(AUCscore,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : TN = 9761,FN = 45, FP = 239 TP = 55 \n",
      "F1 Score = 0.279\n",
      "Accuracy = 0.972\n",
      "AUC score = 0.938\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_b.csv')\n",
    "dataAUC = pd.read_csv('5_b.csv')\n",
    "\n",
    "data.sort_values(by='proba', ascending=True , inplace = True) #sort data by proba in ascending order\n",
    "\n",
    "data['proba'] = np.where(data['proba'] >= 0.5, 1, data['proba'])    #replacing proba with 1 if >= 0.5\n",
    "data['proba'] = np.where(data['proba'] < 0.5, 0, data['proba'])     #replacing proba with 0 if < 0.5\n",
    "\n",
    "data['y'] = data['y'].astype(int)                    #convering to int\n",
    "data['proba'] = data['proba'].astype(int)            #convering to int\n",
    "\n",
    "\n",
    "data_TN = data.query('y == 0 & proba == 0')          #filtering TN\n",
    "data_FN = data.query('y == 1 & proba == 0')          #filtering FN\n",
    "data_FP = data.query('y == 0 & proba == 1')          #filtering FP\n",
    "data_TP = data.query('y == 1 & proba == 1')          #filtering TP\n",
    "\n",
    "TN = data_TN.shape[0]                                #Getting number of records\n",
    "FN = data_FN.shape[0]\n",
    "FP = data_FP.shape[0]\n",
    "TP = data_TP.shape[0]\n",
    "\n",
    "print(\"Confusion Matrix : TN = {},FN = {}, FP = {} TP = {} \".format(TN , FN , FP , TP))     #printing Confusion Matrix\n",
    "\n",
    "pr = TP/(TP+FP)   #Calculating Precision\n",
    "re = TP/(TP+FN)   #Calculating Recall\n",
    "\n",
    "f1 = (2*pr*re)/(pr+re)   #Calculating F1 Score\n",
    "\n",
    "acc = (TN+TP)/(TP+FP+FN+TN)  #Calculating Accuracy Score\n",
    "\n",
    "print(\"F1 Score = {}\".format(round(f1,3)))   #printing F1 Score\n",
    "print(\"Accuracy = {}\".format(round(acc,3)))  #printing Accuracy Score\n",
    "\n",
    "\n",
    "\n",
    "### For AUC Score\n",
    "dataAUC.sort_values(by='proba', ascending=False , inplace = True) #sorting in descending order of probas\n",
    "\n",
    "arr_proba = np.array(dataAUC.proba.unique()) # array of unique probabilities\n",
    "\n",
    "TPR_Final =  []\n",
    "FPR_Final  = []\n",
    "\n",
    "\n",
    "for i in arr_proba:\n",
    "    data_new_ite = dataAUC.copy()   #used copy to point to different memory location , copying original dataset for every iteration\n",
    "\n",
    "    data_new_ite['proba'] = np.where(data_new_ite['proba'] >= i, 1.0, data_new_ite['proba'])\n",
    "    data_new_ite['proba'] = np.where(data_new_ite['proba'] < i, 0.0, data_new_ite['proba'])\n",
    "    \n",
    "    data_P = data_new_ite.query('y == 1.0')\n",
    "    data_N = data_new_ite.query('y == 0.0')\n",
    "    data_FP = data_new_ite.query('y == 0.0 & proba == 1.0')\n",
    "    data_TP = data_new_ite.query('y == 1.0 & proba == 1.0')\n",
    "    \n",
    "    P = data_P.shape[0]\n",
    "    N = data_N.shape[0]\n",
    "    FP = data_FP.shape[0]\n",
    "    TP = data_TP.shape[0]\n",
    "    \n",
    "    TPR = TP/P\n",
    "    FPR = FP/N\n",
    "    \n",
    "    TPR_Final.append(TPR)   #creating list of TPR for every threshold\n",
    "    FPR_Final.append(FPR)   #creating list of FPR for every threshold\n",
    "    \n",
    "AUCscore = np.trapz(TPR_Final, FPR_Final)  #calculation AUC Score\n",
    "print(\"AUC score = {}\".format(round(AUCscore,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold which gives minimum value of A 0.49\n"
     ]
    }
   ],
   "source": [
    "dataAUC = pd.read_csv('5_c.csv')\n",
    "dataAUC.sort_values(by='prob', ascending=False , inplace = True) #sorting in descending order of probas\n",
    "\n",
    "arr_proba = np.array(dataAUC.prob.unique()) # array of unique probabilities\n",
    "\n",
    "Final_A =  []  #Final values of metric A\n",
    "thresh = []  # All unique threshold values\n",
    "\n",
    "\n",
    "\n",
    "for i in arr_proba:\n",
    "    data_new_ite = dataAUC.copy()   #used copy to point to different memory location , copying original dataset for every iteration\n",
    "\n",
    "    data_new_ite['prob'] = np.where(data_new_ite['prob'] >= i, 1.0, data_new_ite['prob'])\n",
    "    data_new_ite['prob'] = np.where(data_new_ite['prob'] < i, 0.0, data_new_ite['prob'])\n",
    "    \n",
    "    data_FP = data_new_ite.query('y == 0.0 & prob == 1.0')\n",
    "    data_FN = data_new_ite.query('y == 1.0 & prob == 0.0')\n",
    "    \n",
    "    FP = data_FP.shape[0]\n",
    "    FN = data_FN.shape[0]\n",
    "    \n",
    "    A = (500*FN) + (500*FP) #calculating metric\n",
    "    Final_A.append(A)  \n",
    "    thresh.append(i)   \n",
    "\n",
    "best_thresh = thresh[Final_A.index(min(Final_A))]  #Finding best thresh by getting loc of min value of A in list Final_A\n",
    "\n",
    "print(\"Best threshold which gives minimum value of A {}\".format(round(best_thresh,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error : 177.166\n",
      "Mean Absolute percentage error : 12.927\n",
      "R Squared Error : 0.956\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_d.csv')\n",
    "\n",
    "###MSE\n",
    "n = data.shape[0] #total data points\n",
    "summ = 0\n",
    "\n",
    "for i in data.index: \n",
    "    summ += ( (data['y'][i] - data['pred'][i])  *  (data['y'][i] - data['pred'][i]) )   #sum of squares of error for every point\n",
    "\n",
    "MSE = summ/n  #calculating MSE\n",
    "\n",
    "print(\"Mean Square Error : {}\".format(round(MSE,3)))\n",
    "\n",
    "###MAPE\n",
    "summ_err_mape = 0\n",
    "a_bar = data['pred'].sum()  #taking sum of all y\n",
    "\n",
    "for i in data.index: \n",
    "    summ_err_mape += abs( (data['y'][i] - data['pred'][i])  )   #sum of absolute value of error\n",
    "\n",
    "MAPE = (summ_err_mape/a_bar)*100   #calculating  MAPE\n",
    "\n",
    "print(\"Mean Absolute percentage error : {}\".format(round(MAPE,3)))\n",
    "\n",
    "###R^2 Error\n",
    "\n",
    "y_bar = data['y'].mean()          #calculating mean of all points y\n",
    "\n",
    "ss_sum = 0\n",
    "for i in data.index: \n",
    "    ss_sum += ( (data['y'][i] - y_bar)  *  (data['y'][i] - y_bar) )   # sum of squares of y - avg(y)\n",
    "    \n",
    "r2Error = 1- (summ/ss_sum)   # using summ calculated for MSE , calculating R2Error\n",
    "\n",
    "print(\"R Squared Error : {}\".format(round(r2Error,3)))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
